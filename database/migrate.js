import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import pg from 'pg';
import dotenv from 'dotenv';

const { Pool } = pg;
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// è¼‰å…¥ç’°å¢ƒè®Šæ•¸
dotenv.config({ path: path.join(__dirname, '../backend/.env') });

async function migrate() {
  const pool = new Pool({
    connectionString: process.env.DATABASE_URL,
  });

  try {
    console.log('ğŸ”„ é–‹å§‹åŸ·è¡Œè³‡æ–™åº«é·ç§»...');
    console.log(`ğŸ“Š è³‡æ–™åº«: ${process.env.DATABASE_URL?.split('@')[1] || 'æœªè¨­å®š'}`);

    // è®€å– schema.sql
    const schemaPath = path.join(__dirname, 'schema.sql');
    const schemaSql = fs.readFileSync(schemaPath, 'utf8');

    // åŸ·è¡Œ schema
    await pool.query(schemaSql);

    console.log('âœ… è³‡æ–™åº«é·ç§»å®Œæˆï¼');
    console.log('\nå»ºç«‹çš„è³‡æ–™è¡¨:');
    console.log('  - employees (å“¡å·¥è¡¨)');
    console.log('  - records (è£œä¼‘è¨˜éŒ„è¡¨)');
    console.log('  - deduction_mappings (FIFO æ‰£é™¤å°æ‡‰è¡¨)');
    console.log('  - session (Session è¡¨)');

    // æª¢æŸ¥è³‡æ–™è¡¨
    const result = await pool.query(`
      SELECT table_name
      FROM information_schema.tables
      WHERE table_schema = 'public'
      ORDER BY table_name;
    `);

    console.log('\nç›®å‰è³‡æ–™è¡¨æ¸…å–®:');
    result.rows.forEach(row => {
      console.log(`  âœ“ ${row.table_name}`);
    });

  } catch (error) {
    console.error('âŒ è³‡æ–™åº«é·ç§»å¤±æ•—:', error.message);
    console.error(error);
    process.exit(1);
  } finally {
    await pool.end();
  }
}

migrate();
